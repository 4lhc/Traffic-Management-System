{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Managment System with OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "Control traffic lights based on the vehicle density at four _regions of interest_.\n",
    "Live video stream obtained from [here](https://www.insecam.org/en/view/751910/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video Stream\n",
    "\n",
    "<img src=\"test/img/template.jpg\" alt=\"traffic intersection\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://kevinsaye.wordpress.com/2018/10/17/making-a-rtsp-server-out-of-a-raspberry-pi-in-15-minutes-or-less/\n",
    "http://0.0.0.0:5000/video_feed\"cap = cv2.VideoCapture(\"http://0.0.0.0:5000/video_feed\") #SNC-CH110 - sony network camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sj/Code/2019/KITS/Traffic-Management-System/test/speed-detector/env/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "\n",
    "stream_url = \"http://0.0.0.0:5000/video_feed\"\n",
    "\n",
    "with urlopen(stream_url) as stream:\n",
    "    \n",
    "    bytes = b''\n",
    "    while True:\n",
    "        bytes += stream.read(64*1024)\n",
    "        a = bytes.find(b'\\xff\\xd8') #start bytes of mjpeg\n",
    "        b = bytes.find(b'\\xff\\xd9') #end bytes of mjpeg\n",
    "        if a != -1 and b != -1:     #detect start and end pos\n",
    "            jpg = bytes[a:b+2]      #extract jpeg\n",
    "            bytes = bytes[b+2:]     #next jpeg item\n",
    "            img = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.IMREAD_GRAYSCALE) #decode jpg raw bytes to np array\n",
    "#           gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.imshow(\"img\", img)\n",
    "#             cv2.imshow(\"gray\", gray)\n",
    "           \n",
    "        if cv2.waitKey(1) == 27: #wait for <ESC>\n",
    "            stream.close()\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Background Extraction\n",
    "\n",
    "Calculate the weighted sum of the input image src and the accumulator dst so that dst becomes a running average of the frame sequence. [link](https://docs.opencv.org/2.4/modules/imgproc/doc/motion_analysis_and_object_tracking.html?highlight=accumulate#accumulateweighted)\n",
    "\n",
    "<img src=\"https://docs.opencv.org/2.4/_images/math/7480f2f9ee402e9e85823d2644b8e1f8c263191a.png\" alt=\"eqn\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(1) #in case video stream is inaccessible\n",
    "cap = cv2.VideoCapture(\"http://0.0.0.0:5000/video_feed\")\n",
    "alpha = 0.01\n",
    "ret, frame = cap.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #src\n",
    "avg = np.float32(gray) #dst\n",
    "\n",
    "while ret:\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.accumulateWeighted(gray, avg, alpha) #running avg calculation\n",
    "    res_avg = cv2.convertScaleAbs(avg)\n",
    "    \n",
    "    cv2.imwrite(\"test/img/average.jpg\", res_avg)\n",
    "    cv2.imshow(\"accumulateWeighted\", res_avg)\n",
    "    cv2.imshow(\"input\", frame)\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#cv2.imwrite(\"average.jpg\", res_avg)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Average Image\n",
    "<img src=\"test/img/average.jpg\" alt=\"Running verage\" width=\"600\"/>\n",
    "\n",
    "**ISSUE:** Incomplete background extrcation using the above method.\n",
    "\n",
    "**Possible Soln. :** \n",
    "\n",
    "- Changing alpha value. \n",
    "\n",
    "- Calculate running avg. for a larger number of frames.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Masks\n",
    "Created in gimp\n",
    "\n",
    "MASK 1|  MASK 2|MASK 3|MASK 4\n",
    "----|-------|---------|---------\n",
    "![](test/img/mask_roi_1.jpg) | ![](test/img/mask_roi_2.jpg) | ![](test/img/mask_roi_3.jpg) | ![](test/img/mask_roi_4.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template Creation\n",
    "with masks and average frame [cv2.bitwise_and()](https://docs.opencv.org/2.4.8/modules/core/doc/operations_on_arrays.html#bitwise-and)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask_files = ['test/img/mask_roi_1.jpg',\n",
    "              'test/img/mask_roi_2.jpg',\n",
    "              'test/img/mask_roi_3.jpg',\n",
    "              'test/img/mask_roi_4.jpg']\n",
    "\n",
    "template_files = ['test/img/template_roi_1.jpg',\n",
    "                  'test/img/template_roi_2.jpg',\n",
    "                  'test/img/template_roi_3.jpg',\n",
    "                  'test/img/template_roi_4.jpg']\n",
    "\n",
    "crop = [{\"x1\": 970, \"y1\": 400, \"x2\":1279, \"y2\":500},\n",
    "        {\"x1\": 755, \"y1\": 275, \"x2\":940, \"y2\":365},\n",
    "        {\"x1\": 335, \"y1\": 335, \"x2\":528, \"y2\":400},\n",
    "        {\"x1\": 300, \"y1\": 470, \"x2\":670, \"y2\":675}]\n",
    "\n",
    "\n",
    "masks = [cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE) for mask_file in mask_files]\n",
    "average = cv2.imread(\"test/img/average.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "for index, (name, mask) in enumerate(zip(template_files, masks)):  \n",
    "    \n",
    "    template = cv2.bitwise_and(average, average, mask=mask) ####creating template\n",
    "    \n",
    "    x1 = crop[index][\"x1\"]\n",
    "    y1 = crop[index][\"y1\"]\n",
    "    x2 = crop[index][\"x2\"]\n",
    "    y2 = crop[index][\"y2\"]\n",
    "    \n",
    "    template = template[y1:y2, x1:x2]\n",
    "#     cv2.imwrite(name, template)\n",
    "    cv2.imshow(name, template)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template 1|  Template 2|Template 3|Template 4\n",
    "----|-------|---------|---------\n",
    "![](test/img/template_roi_1.jpg) | ![](test/img/template_roi_2.jpg) | ![](test/img/template_roi_3.jpg) | ![](test/img/template_roi_4.jpg)\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROI Extraction \n",
    "with masks and frame [cv2.bitwise_and()](https://docs.opencv.org/2.4.8/modules/core/doc/operations_on_arrays.html#bitwise-and)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"test/vid/h264-night.mp4\") #in case video stream is inaccessible\n",
    "mask_files = ['test/img/mask_roi_1.jpg',\n",
    "              'test/img/mask_roi_2.jpg',\n",
    "              'test/img/mask_roi_3.jpg',\n",
    "              'test/img/mask_roi_4.jpg']\n",
    "masks = [cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE) for mask_file in mask_files]\n",
    "\n",
    "crop = [{\"x1\": 970, \"y1\": 400, \"x2\":1279, \"y2\":500},\n",
    "        {\"x1\": 755, \"y1\": 275, \"x2\":940, \"y2\":365},\n",
    "        {\"x1\": 335, \"y1\": 335, \"x2\":528, \"y2\":400},\n",
    "        {\"x1\": 300, \"y1\": 470, \"x2\":670, \"y2\":675}]\n",
    "\n",
    "ret, frame = cap.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow(\"input\", frame)\n",
    "    \n",
    "    for index, (name, mask) in enumerate(zip(mask_files, masks)):  \n",
    "        res = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "        x1 = crop[index][\"x1\"]\n",
    "        y1 = crop[index][\"y1\"]\n",
    "        x2 = crop[index][\"x2\"]\n",
    "        y2 = crop[index][\"y2\"]\n",
    "        \n",
    "\n",
    "        res = res[y1:y2, x1:x2] #croppin\n",
    "#         cv2.imwrite(\"test/img/roi_{}.jpg\".format(index+1), res)\n",
    "    \n",
    "        cv2.imshow(name, res)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ROI 1|  ROI 2|ROI 3|ROI 4\n",
    "----|-------|---------|---------\n",
    "![](test/img/roi_1.jpg) | ![](test/img/roi_2.jpg) | ![](test/img/roi_3.jpg) | ![](test/img/roi_4.jpg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Template Matching\n",
    "[link](https://docs.opencv.org/2.4.8/modules/imgproc/doc/object_detection.html?highlight=matchtemplate#cv2.matchTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_files = ['test/img/template_roi_1.jpg',\n",
    "                  'test/img/template_roi_2.jpg',\n",
    "                  'test/img/template_roi_3.jpg',\n",
    "                  'test/img/template_roi_4.jpg']\n",
    "# cap = cv2.VideoCapture(\"rtsp://93.157.18.93/media/video1\") #SNC-CH110 - sony network camera\n",
    "cap = cv2.VideoCapture(\"test/vid/h264-night.mp4\") #in case video stream is inaccessible\n",
    "templates = [cv2.imread(template_file, cv2.IMREAD_GRAYSCALE) for template_file in template_files]\n",
    "\n",
    "# mask_files = [\"mask_roi_4.jpg\"]\n",
    "mask_files = ['test/img/mask_roi_1.jpg',\n",
    "              'test/img/mask_roi_2.jpg',\n",
    "              'test/img/mask_roi_3.jpg',\n",
    "              'test/img/mask_roi_4.jpg']\n",
    "masks = [cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE) for mask_file in mask_files]\n",
    "\n",
    "crop = [{\"x1\": 970, \"y1\": 400, \"x2\":1279, \"y2\":500},\n",
    "        {\"x1\": 755, \"y1\": 275, \"x2\":940, \"y2\":365},\n",
    "        {\"x1\": 335, \"y1\": 335, \"x2\":528, \"y2\":400},\n",
    "        {\"x1\": 300, \"y1\": 470, \"x2\":670, \"y2\":675}]\n",
    "\n",
    "\n",
    "ret, frame = cap.read()\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.imshow(\"input\", frame)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    for index, (mask, template) in enumerate(zip(masks, templates)):\n",
    "        roi = cv2.bitwise_and(gray, gray, mask=mask)\n",
    "        x1 = crop[index][\"x1\"]\n",
    "        y1 = crop[index][\"y1\"]\n",
    "        x2 = crop[index][\"x2\"]\n",
    "        y2 = crop[index][\"y2\"]\n",
    "        \n",
    "\n",
    "        roi = roi[y1:y2, x1:x2] \n",
    "        res = cv2.matchTemplate(roi, template, cv2.TM_CCORR_NORMED)\n",
    "#       res = cv2.subtract(roi, template)\n",
    "#       nozero = cv2.countNonZero(res)\n",
    "        cv2.putText(roi,\"{:.3f}\".format(res[0][0]),(10,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "#       cv2.imshow(\"Template {}\".format(index), template)\n",
    "        cv2.imshow(\"Roi {}\".format(index), roi)\n",
    "        cv2.imwrite(\"test/img/roi_density_{}.jpg\".format(index+1), roi)\n",
    "    \n",
    "        \n",
    "\n",
    "    ret, frame = cap.read()\n",
    "            \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "ROI 1|  ROI 2|ROI 3|ROI 4\n",
    "----|-------|---------|---------\n",
    "![](test/img/roi_density_1.jpg) | ![](test/img/roi_density_2.jpg) | ![](test/img/roi_density_3.jpg) | ![](test/img/roi_density_4.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
